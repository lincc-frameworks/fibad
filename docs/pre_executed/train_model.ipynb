{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIBAD Getting Started\n",
    "\n",
    "In this getting started notebook we'll create an instance of a FIBAD object, train a builtin model on the CiFAR training dataset, and then use that trained model to run inference on the CiFAR testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a FIBAD instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drew/miniconda3/envs/fibad/lib/python3.12/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "[2025-02-04 12:58:33,912 fibad:INFO] Runtime Config read from: /home/drew/code/fibad/src/fibad/fibad_default_config.toml\n"
     ]
    }
   ],
   "source": [
    "import fibad\n",
    "\n",
    "f = fibad.Fibad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.config[\"model\"][\"name\"] = \"ExampleAutoencoder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we'll make a few adjustments to the default configuration settings that the `fibad` object was instantiated with.\n",
    "By accessing the `.config` attribute of the fibad instance, we can modify any configuration value.\n",
    "There are many configuration values that can be set, but here, we update only the model to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-04 12:58:34,729 fibad.models.model_registry:INFO] Using criterion: torch.nn.CrossEntropyLoss with default arguments.\n",
      "2025-02-04 12:58:34,901 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CifarDataSet': \n",
      "\t{'sampler': <torch.utils.data.sampler.SubsetRandomSampler object at 0x7f52c3b66e40>, 'batch_size': 512, 'num_workers': 2, 'pin_memory': True}\n",
      "2025-02-04 12:58:34,902 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CifarDataSet': \n",
      "\t{'sampler': <torch.utils.data.sampler.SubsetRandomSampler object at 0x7f528a178320>, 'batch_size': 512, 'num_workers': 2, 'pin_memory': True}\n",
      "/home/drew/miniconda3/envs/fibad/lib/python3.12/site-packages/ignite/handlers/tqdm_logger.py:127: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2025/02/04 12:58:35 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "[2025-02-04 12:58:35,289 fibad.pytorch_ignite:INFO] Training model on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bf1422ffb746d5bf76421a9e10c6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  1%|1         | 1/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b529f4758d4583ba1c500e0870535e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  1%|1         | 1/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb4d2c6202c4158b018871832a234f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  1%|1         | 1/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7fbbe16d06417b8057c93a4716b456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  1%|1         | 1/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6b695fb76342b59c0f4512a9464448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  1%|1         | 1/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d2dcee259146e5af4c491cdb0ed62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  1%|1         | 1/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c8b03e9b7c430b8e12ab5470fbc727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  1%|1         | 1/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6645aa80ea4be19990f17258781c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  1%|1         | 1/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebbf4c956fb4583b905276347170aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  1%|1         | 1/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a02aa1915554a059d60840c5f1d99aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  1%|1         | 1/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-04 12:59:25,991 fibad.pytorch_ignite:INFO] Total training time: 50.70[s]\n",
      "[2025-02-04 12:59:25,992 fibad.pytorch_ignite:INFO] Latest checkpoint saved as: /home/drew/code/fibad/docs/pre_executed/results/20250204-125833-train-ka1H/checkpoint_epoch_10.pt\n",
      "[2025-02-04 12:59:25,992 fibad.pytorch_ignite:INFO] Best metric checkpoint saved as: /home/drew/code/fibad/docs/pre_executed/results/20250204-125833-train-ka1H/checkpoint_10_loss=-120.1850.pt\n",
      "2025/02/04 12:59:26 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/02/04 12:59:26 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[2025-02-04 12:59:26,028 fibad.train:INFO] Finished Training\n"
     ]
    }
   ],
   "source": [
    "f.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the training will be stored in a time-stamped directory under the `./results/`.\n",
    "By default, a copy of the final configuration used in training is persisted as `runtime_config.toml`.\n",
    "To run fibad again with the same configuration, you can reference this runtime_config.toml file.\n",
    "\n",
    "If running in another notebook, instantiate a fibad object like so:\n",
    "```\n",
    "new_fibad_instance = fibad.Fibad(config_file='./results/<timestamped_directory>/runtime_config.toml')\n",
    "```\n",
    "\n",
    "Or from the command line:\n",
    "```\n",
    ">> fibad train --runtime-config ./results/<timestamped_directory>/runtime_config.toml\n",
    "```\n",
    "\n",
    "Note here we're training on only a small handful of CiFAR data, but FIBAD has demonstrated that it can scale up to training sets with >1M samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-04 12:59:26,734 fibad.models.model_registry:INFO] Using criterion: torch.nn.CrossEntropyLoss with default arguments.\n",
      "[2025-02-04 12:59:26,736 fibad.infer:INFO] data set has length 50000\n",
      "2025-02-04 12:59:26,736 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CifarDataSet': \n",
      "\t{'sampler': None, 'batch_size': 128, 'num_workers': 2, 'pin_memory': True}\n",
      "[2025-02-04 12:59:27,068 fibad.pytorch_ignite:INFO] Evaluating model on device: cuda\n",
      "[2025-02-04 12:59:27,068 fibad.pytorch_ignite:INFO] Total epochs: 1\n",
      "[2025-02-04 12:59:44,114 fibad.pytorch_ignite:INFO] Total evaluation time: 17.05[s]\n",
      "[2025-02-04 12:59:44,164 fibad.infer:INFO] Inference results saved in: /home/drew/code/fibad/docs/pre_executed/results/20250204-125926-infer-xT9b\n"
     ]
    }
   ],
   "source": [
    "f.config[\"data_set\"][\"test_size\"] = 1.0\n",
    "f.config[\"data_set\"][\"train_size\"] = 0.0\n",
    "f.config[\"data_set\"][\"validate_size\"] = 0.0\n",
    "f.config[\"data_loader\"][\"batch_size\"] = 128\n",
    "\n",
    "f.infer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a model has been trained, we can use the model weights file to run inference.\n",
    "By default running `infer` will look for the latest available model weights file.\n",
    "A specific model weights file can be specified with `f.config['infer']['model_weights_file'] = <path_to_model_weights_file>`.\n",
    "\n",
    "Here we'll make use of the last trained model weights file, and update the data set splits so that 100% of the data will be used for inference.\n",
    "\n",
    "With the configuration updated, we can run inference by calling `f.infer()`.\n",
    "\n",
    "The results of running inference are saved in the output directory noted in the last log line.\n",
    "The default output format is batched .npy files.\n",
    "Additionally a ChromaDB vector database will be populated with the inference results to enable efficient similarity search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fibad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
