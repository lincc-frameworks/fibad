{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyrax Getting Started\n",
    "\n",
    "In this getting started notebook we'll create an instance of a Hyrax object, train a builtin model on the CiFAR training dataset, and then use that trained model to run inference on the CiFAR testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Hyrax instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-26 14:46:50,459 hyrax:INFO] Runtime Config read from: /home/drew/code/fibad/src/hyrax/hyrax_default_config.toml\n"
     ]
    }
   ],
   "source": [
    "import hyrax\n",
    "\n",
    "h = hyrax.Hyrax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.config[\"model\"][\"name\"] = \"HyraxAutoencoder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we'll make a few adjustments to the default configuration settings that the `hyrax` object was instantiated with.\n",
    "By accessing the `.config` attribute of the hyrax instance, we can modify any configuration value.\n",
    "There are many configuration values that can be set, but here, we update only the model to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drew/miniconda3/envs/fibad/lib/python3.12/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-26 14:46:54,584 hyrax.models.model_registry:INFO] Using criterion: torch.nn.CrossEntropyLoss with default arguments.\n",
      "2025-03-26 14:46:54,653 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset HyraxCifarDa': \n",
      "\t{'sampler': <torch.utils.data.sampler.SubsetRandomSampler object at 0x7f2095f60920>, 'batch_size': 512, 'pin_memory': True}\n",
      "2025-03-26 14:46:54,655 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset HyraxCifarDa': \n",
      "\t{'sampler': <torch.utils.data.sampler.SubsetRandomSampler object at 0x7f2095f60980>, 'batch_size': 512, 'pin_memory': True}\n",
      "/home/drew/miniconda3/envs/fibad/lib/python3.12/site-packages/ignite/handlers/tqdm_logger.py:127: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2025/03/26 14:46:54 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "[2025-03-26 14:46:54,902 hyrax.pytorch_ignite:INFO] Training model on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f78099ff2c542ca9035b20542ddfdb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  2%|1         | 1/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9dfe21f63d54a52ac433e4c0dd585f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  2%|1         | 1/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7255c3a12e2e4722aa11b7c74edf095a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  2%|1         | 1/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0403a67fbb3040c898f3f99fbfc21b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  2%|1         | 1/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b37f565ffc343cc80a24ebcd5bfac77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  2%|1         | 1/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c55d57ea274a95bd7f9006e2f056c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  2%|1         | 1/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ead518da40c4ee695364d7a842d0600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  2%|1         | 1/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fadee1c9ff418e87fcfa4aea4d9cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  2%|1         | 1/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a82d0db82f94f658ebd0a32208debea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  2%|1         | 1/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb1e775a8174e2195876759e88a093e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  2%|1         | 1/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-26 14:48:23,891 hyrax.pytorch_ignite:INFO] Total training time: 88.99[s]\n",
      "[2025-03-26 14:48:23,891 hyrax.pytorch_ignite:INFO] Latest checkpoint saved as: /home/drew/code/fibad/docs/pre_executed/results/20250326-144653-train-OgeH/checkpoint_epoch_10.pt\n",
      "[2025-03-26 14:48:23,892 hyrax.pytorch_ignite:INFO] Best metric checkpoint saved as: /home/drew/code/fibad/docs/pre_executed/results/20250326-144653-train-OgeH/checkpoint_10_loss=-127.4221.pt\n",
      "2025/03/26 14:48:23 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/03/26 14:48:23 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[2025-03-26 14:48:23,903 hyrax.train:INFO] Finished Training\n",
      "[2025-03-26 14:48:24,250 hyrax.model_exporters:INFO] Exported model to ONNX format: /home/drew/code/fibad/docs/pre_executed/results/20250326-144653-train-OgeH/example_model_opset_20.onnx\n"
     ]
    }
   ],
   "source": [
    "h.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the training will be stored in a time-stamped directory under the `./results/`.\n",
    "By default, a copy of the final configuration used in training is persisted as `runtime_config.toml`.\n",
    "To train again with the same configuration, you can reference this runtime_config.toml file.\n",
    "\n",
    "If running in another notebook, instantiate a hyrax object like so:\n",
    "```\n",
    "new_hyrax_instance = hyrax.Hyrax(config_file='./results/<timestamped_directory>/runtime_config.toml')\n",
    "```\n",
    "\n",
    "Or from the command line:\n",
    "```\n",
    ">> hyrax train --runtime-config ./results/<timestamped_directory>/runtime_config.toml\n",
    "```\n",
    "\n",
    "Note here we're training on only a small handful of CiFAR data, but Hyrax has demonstrated that it can scale up to training sets with >1M samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-26 14:48:25,186 hyrax.models.model_registry:INFO] Using criterion: torch.nn.CrossEntropyLoss with default arguments.\n",
      "[2025-03-26 14:48:25,187 hyrax.infer:INFO] data set has length 50000\n",
      "2025-03-26 14:48:25,188 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset HyraxCifarDa': \n",
      "\t{'sampler': None, 'batch_size': 128, 'pin_memory': True}\n",
      "[2025-03-26 14:48:25,715 hyrax.pytorch_ignite:INFO] Evaluating model on device: cuda\n",
      "[2025-03-26 14:48:25,717 hyrax.pytorch_ignite:INFO] Total epochs: 1\n",
      "[2025-03-26 14:48:51,778 hyrax.pytorch_ignite:INFO] Total evaluation time: 26.06[s]\n",
      "[2025-03-26 14:48:51,848 hyrax.infer:INFO] Inference results saved in: /home/drew/code/fibad/docs/pre_executed/results/20250326-144824-infer-qr2F\n"
     ]
    }
   ],
   "source": [
    "h.config[\"data_set\"][\"test_size\"] = 1.0\n",
    "h.config[\"data_set\"][\"train_size\"] = 0.0\n",
    "h.config[\"data_set\"][\"validate_size\"] = 0.0\n",
    "h.config[\"data_loader\"][\"batch_size\"] = 128\n",
    "\n",
    "h.infer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a model has been trained, we can use the model weights file to run inference.\n",
    "By default running `infer` will look for the latest available model weights file.\n",
    "A specific model weights file can be specified with `h.config['infer']['model_weights_file'] = <path_to_model_weights_file>`.\n",
    "\n",
    "Here we'll make use of the last trained model weights file, and update the data set splits so that 100% of the data will be used for inference.\n",
    "\n",
    "With the configuration updated, we can run inference by calling `h.infer()`.\n",
    "\n",
    "The results of running inference are saved in the output directory noted in the last log line.\n",
    "The default output format is batched .npy files.\n",
    "Additionally a ChromaDB vector database will be populated with the inference results to enable efficient similarity search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fibad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
