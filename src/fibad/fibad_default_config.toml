[general]
use_gpu = true

# Destination of log messages
# 'stderr' and 'stdout' specify the console.
log_destination = "stderr"
# A path name specifies a file e.g.
# log = "fibad_log.txt"

# Lowest log level to emit.
# As you go down the list, fibad will become more verbose in the log.
#
# log_level = "critical" # Only emit the most severe of errors
# log_level = "error"    # Emit all errors
# log_level = "warning"  # Emit warnings and all errors
log_level = "info"     # Emit informational messages, warnings and all errors
# log_level = "debug"    # Very verbose, emit all log messages.

[download]
sw = "22asec"
sh = "22asec"
filter = ["HSC-G", "HSC-R", "HSC-I", "HSC-Z", "HSC-Y"]
type = "coadd"
rerun = "pdr3_wide"
username = "mtauraso@local"
password = "cCw+nX53lmNLHMy+JbizpH/dl4t7sxljiNm6a7k1"
max_connections = 2
fits_file = "../hscplay/temp.fits"
cutout_dir = "../hscplay/cutouts/"
offset = 0
num_sources = 1000

[model]
name = "ExampleAutoencoder"

# An example of requesting an external model class
# external_class = "user_package.submodule.ExternalModel"

weights_filepath = "example_model.pth"
epochs = 10

[data_loader]
# Name of data loader to use
name = "HSCDataLoader"

# An example of requesting an external data loader class
# external_class = "user_package.submodule.ExternalDataLoader"

# Directory path where the data is stored
# path = "./data"
path = "../hscplay/cutouts/"

# Default PyTorch DataLoader parameters
batch_size = 4
shuffle = true
num_workers = 2

[predict]
batch_size = 32
