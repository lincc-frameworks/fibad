[general]
use_gpu = true

# Destination of log messages
# 'stderr' and 'stdout' specify the console.
log_destination = "stderr"
# A path name specifies a file e.g.
# log = "fibad_log.txt"

# Lowest log level to emit.
# As you go down the list, fibad will become more verbose in the log.
#
# log_level = "critical" # Only emit the most severe of errors
# log_level = "error"    # Emit all errors
# log_level = "warning"  # Emit warnings and all errors
log_level = "info"     # Emit informational messages, warnings and all errors
# log_level = "debug"    # Very verbose, emit all log messages.

[download]
sw = "22asec"
sh = "22asec"
filter = ["HSC-G", "HSC-R", "HSC-I", "HSC-Z", "HSC-Y"]
type = "coadd"
rerun = "pdr3_wide"
username = "mtauraso@local"
password = "cCw+nX53lmNLHMy+JbizpH/dl4t7sxljiNm6a7k1"
max_connections = 2
fits_file = "../hscplay/temp.fits"
cutout_dir = "../hscplay/cutouts/"
offset = 0
num_sources = 500

# These control the downloader's HTTP requests and retries
# `retry_wait` How long to wait before retrying a failed HTTP request in seconds. Default 30s
retry_wait = 30
# `retries` How many times to retry a failed HTTP request before moving on to the next one. Default 3 times
retries = 3
# `timepout` How long should we wait to get a full HTTP response from the server. Default 3600s (1hr)
timeout = 3600
# `chunksize` How many sky location rectangles should we request in a single request. Default is 990
chunksize = 990

[model]
name = "ExampleAutoencoder"

# An example of requesting an external model class
# external_class = "user_package.submodule.ExternalModel"

weights_filepath = "example_model.pth"
epochs = 10

[data_loader]
# Name of data loader to use
name = "HSCDataLoader"

# An example of requesting an external data loader class
# external_class = "user_package.submodule.ExternalDataLoader"

# Directory path where the data is stored
path = "./data"

# Pixel dimensions used to crop all images prior to loading. Will prune any images that are too small.
#
# If not provided, the default is to scan the directory for the smallest dimensioned files, and use 
# those pixel dimensions as the crop size.
#
#crop_to = [100,100]

# Limit data loader to only particular filters when there are more in the data set.
#
# When not provided, the number of filters will be automatically gleaned from the data set.
# Defaults to not provided.
#
#filters = ["HSC-G", "HSC-R", "HSC-I", "HSC-Z", "HSC-Y"]

# Default PyTorch DataLoader parameters
batch_size = 500
shuffle = true
num_workers = 10

[predict]
batch_size = 32
