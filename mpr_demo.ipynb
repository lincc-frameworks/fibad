{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fibad Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a sample HSC dataset\n",
    "\n",
    "This dataset is comprised of approximately 1000 cutouts from the Hyper Suprime Cam survey.\n",
    "The cutouts were requested to be 8 arcsecs on a side.\n",
    "For consistency, we crop each image to [96, 96] pixels at runtime.\n",
    "For each object 3 bands have been acquired, I, R, G.\n",
    "\n",
    "Once unzipped there will be a .fits file for each (object id, band) in the `./data/hsc_8asec_1000` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pooch\n",
    "import pooch\n",
    "\n",
    "file_path = pooch.retrieve(\n",
    "    # DOI for Example HSC dataset\n",
    "    url=\"doi:10.5281/zenodo.14498537/hsc_demo_data.zip\",\n",
    "    known_hash=\"md5:ed18ac315a1f9bbc7c2325fd4f1c683a\",\n",
    "    fname=\"example_hsc.zip\",\n",
    "    path=\"./data\",\n",
    "    processor=pooch.Unzip(extract_dir=\".\"),\n",
    ")\n",
    "\n",
    "print(file_path[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration and Training\n",
    "\n",
    "First we import fibad and create a new fibad object, instantiated (implicitly), with the default configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fibad\n",
    "\n",
    "f = fibad.Fibad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we'll make a few adjustments to the default configuration settings that the `fibad` object was instantiated with. By accessing the `.config` attribute of the fibad instance, we can modify any configuration value. \n",
    "\n",
    "Here we change which model to train, the dataset, the location of the data, number of epochs for training as well as a few other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.config[\"general\"][\"data_dir\"] = \"./data/hsc_8asec_1000\"\n",
    "f.config[\"model\"][\"name\"] = \"ExampleAutoencoder\"\n",
    "f.config[\"data_set\"][\"name\"] = \"HSCDataSet\"\n",
    "f.config[\"data_set\"][\"crop_to\"] = [96, 96]\n",
    "f.config[\"download\"][\"filter\"] = [\"HSC-G\", \"HSC-R\", \"HSC-I\"]\n",
    "f.config[\"train\"][\"epochs\"] = 20\n",
    "f.config[\"data_loader\"][\"batch_size\"] = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the `.train()` method to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the training will be stored in a time-stamped directory under the `./results/`. By default, a copy of the final configuration used in training is persisted as `runtime_config.toml`. To run fibad again with the same configuration, you can reference the runtime_config.toml file.\n",
    "\n",
    "If running in another notebook, instantiate a fibad object like so:\n",
    "```\n",
    "new_fibad_instance = fibad.Fibad(config_file='./results/<timestamped_directory>/runtime_config.toml')\n",
    "```\n",
    "\n",
    "Or from the command line on an HPC system:\n",
    "```\n",
    ">> fibad train --runtime-config ./results/<timestamped_directory>/runtime_config.toml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new model\n",
    "\n",
    "New models can be written in a notebook for easier development.\n",
    "Here an autoencoder is written for comparison against the builtin `ExampleAutoencoder`.\n",
    "\n",
    "For reference, the primary difference is that the builtin autoencoder uses `nn.GeLU` whereas `nn.ReLU` is used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from fibad.models.model_registry import fibad_model\n",
    "\n",
    "\n",
    "@fibad_model  # This decorator registers the model with the FIBAD framework\n",
    "class TrialAutoencoder(nn.Module):\n",
    "    def __init__(self, config, shape):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  # (16, 48, 48)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # (32, 24, 24)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # (64, 12, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # (128, 6, 6)\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # (64, 12, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # (32, 24, 24)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),  # (16, 48, 48)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),  # (3, 96, 96)\n",
    "            nn.Sigmoid(),  # Normalize output to [0, 1]\n",
    "        )\n",
    "\n",
    "    def _eval_encoder(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def _eval_decoder(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._eval_encoder(x)\n",
    "\n",
    "    def train_step(self, x):\n",
    "        z = self._eval_encoder(x)\n",
    "        x_hat = self._eval_decoder(z)\n",
    "\n",
    "        # Here, the loss function is defined in the config\n",
    "        loss = self.criterion(x, x_hat)\n",
    "        loss = loss.sum(dim=[1, 2, 3]).mean(dim=[0])\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return {\"loss\": loss.item()}\n",
    "\n",
    "    # The optimizer can be coded directly, or defined in the configuration file\n",
    "    def _optimizer(self):\n",
    "        return optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model defined in the notebook and registered with Fibad using the `@fibad_model` decorator, the configuration\n",
    "is updated so that in the next call to `f.train()` the new model will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.config[\"model\"][\"name\"] = \"TrialAutoencoder\"\n",
    "f.config[\"criterion\"][\"name\"] = \"torch.nn.MSELoss\"\n",
    "f.config[\"torch.nn.MSELoss\"] = {}\n",
    "f.config[\"torch.nn.MSELoss\"][\"reduction\"] = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare model performance\n",
    "\n",
    "Fibad will automatically logs training information for model evaluation.\n",
    "Currently Tensorboard and MLFlow are supported for easy model-to-model comparisons of metrics and parameters.\n",
    "\n",
    "![alt text](mlflow_mpr_training_loss.JPG)\n",
    "![alt text](mlflow_mpr_param_diffs.JPG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ./results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference using a trained model\n",
    "Once a model has been trained, we can use the model weights file to run inference on.\n",
    "\n",
    "In this example, we'll assume that the the builtin `ExampleAutoencoder` has outperformed the `TrialAutoencoder` defined in the notebook.\n",
    "\n",
    "In order to run inference using a specific trained model, the `'infer'` configuration section is updated.\n",
    "Additionally, to run inference on the entire dataset the data set splits are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to the path of the example.pth file that was created by the call to fibad_instance.train().\n",
    "# It should be something like `.../results/<timestamp>-train/example_model.pth`.\n",
    "# fibad_instance.config[\"infer\"][\"model_weights_file\"] = \"\"\n",
    "\n",
    "# Update the data set splits to be 100% test data\n",
    "f.config[\"data_set\"][\"test_size\"] = 1.0\n",
    "f.config[\"data_set\"][\"train_size\"] = 0.0\n",
    "f.config[\"data_set\"][\"validate_size\"] = 0.0\n",
    "\n",
    "# Set the batch size larger for faster inference\n",
    "f.config[\"data_loader\"][\"batch_size\"] = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will run inference on the specified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.infer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the results of inference\n",
    "\n",
    "Fibad will save the output of inference in batched .npy files in the `.../results/<timestamp>-infer-xxxx` directory.\n",
    "\n",
    "Optionally, Fibad can populate a vector database for fast approximate similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import numpy as np\n",
    "\n",
    "# open a connection to the vector database\n",
    "from fibad.config_utils import find_most_recent_results_dir\n",
    "\n",
    "results_dir = find_most_recent_results_dir(f.config, \"infer\")\n",
    "\n",
    "client = chromadb.PersistentClient(path=str(results_dir))\n",
    "collection = client.get_collection(\"fibad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = collection.get(include=[\"embeddings\"])\n",
    "all_nn = collection.query(query_embeddings=all_embeddings[\"embeddings\"], n_results=5)\n",
    "median_all_nn_dist = np.median(all_nn[\"distances\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose a threshold, plot histogram of values lower to exclude outliers due to instrumental defects\n",
    "_ = plt.hist(median_all_nn_dist, bins=100, range=(0, 30_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [i for i, x in enumerate(median_all_nn_dist) if 18_000 < x and x < 30_000]\n",
    "print(f\"Number of indexes: {len(indexes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Should probably sort the indexes in order of increasing median_all_nn_dist values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_object_ids = []\n",
    "for indx in indexes:\n",
    "    anom_object_ids.append(all_embeddings[\"ids\"][indx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the actual file names for the \"anomalous objects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "names = set()\n",
    "for anom_object_id in anom_object_ids:\n",
    "    found_files = glob.glob(\n",
    "        f\"/home/drew/code/fibad/docs/notebooks/data/hsc_example/hsc_8asec_1000/{anom_object_id}*.fits\"\n",
    "    )\n",
    "    for f in found_files:\n",
    "        names.add(f[:-11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "\n",
    "# Function to normalize the data to the range [0, 1]\n",
    "def normalize(data):\n",
    "    data_min = np.min(data)\n",
    "    data_max = np.max(data)\n",
    "    return (data - data_min) / (data_max - data_min)\n",
    "\n",
    "\n",
    "# Plot our 3 filter images\n",
    "def plotter(ax, file_name):\n",
    "    # Read the FITS files\n",
    "    fits_file_r = file_name + \"_HSC-I.fits\"\n",
    "    fits_file_g = file_name + \"_HSC-R.fits\"\n",
    "    fits_file_b = file_name + \"_HSC-G.fits\"\n",
    "\n",
    "    data_r = fits.getdata(fits_file_r)\n",
    "    data_g = fits.getdata(fits_file_g)\n",
    "    data_b = fits.getdata(fits_file_b)\n",
    "\n",
    "    # Normalize the data\n",
    "    data_r = normalize(data_r)\n",
    "    data_g = normalize(data_g)\n",
    "    data_b = normalize(data_b)\n",
    "\n",
    "    # Combine the data into an RGB image\n",
    "    rgb_image = np.zeros((data_r.shape[0], data_r.shape[1], 3))\n",
    "    rgb_image[..., 0] = data_r  # Red channel\n",
    "    rgb_image[..., 1] = data_g  # Green channel\n",
    "    rgb_image[..., 2] = data_b  # Blue channel\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(rgb_image, origin=\"lower\")\n",
    "    ax.set_title(\n",
    "        \"Obj ID: \" + file_name.split(\"/\")[-1][:17], y=1.0, pad=-14, color=\"white\"\n",
    "    )  # Set the title to the file name\n",
    "    ax.axis(\"off\")  # Hide the axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nx3_grid(data_list):\n",
    "    \"\"\"\n",
    "    Plots an n x 3 grid of matplotlib plots.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_list : list of arrays\n",
    "        List of data arrays to plot.\n",
    "    \"\"\"\n",
    "    num_plots = len(data_list)\n",
    "    num_rows = (num_plots + 2) // 3  # Calculate the number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(15, 5 * num_rows))\n",
    "\n",
    "    for i, data in enumerate(data_list):\n",
    "        row = i // 3\n",
    "        col = i % 3\n",
    "        ax = axes[row, col]\n",
    "        plotter(ax, data)\n",
    "        ax.plot(data, color=\"white\")  # Set plot line color to white\n",
    "        fig.patch.set_facecolor(\"darkslategrey\")  # Set background color to black\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(num_plots, num_rows * 3):\n",
    "        fig.delaxes(axes.flatten()[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nx3_grid(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fibad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
